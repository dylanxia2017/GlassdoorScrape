{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from time import gmtime, strftime\n",
    "from gspread_pandas import Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing the fuctions to scarp the classes from the soup\n",
    "def get_comp(result):\n",
    "    try:\n",
    "        return result.find('span', {'class':'company'}).text\n",
    "    except:\n",
    "        return 'NA'\n",
    "def get_loc(result):\n",
    "    try:\n",
    "        return result.find('span', {'class':'location'}).text\n",
    "    except:\n",
    "        return 'NA'\n",
    "    \n",
    "def get_job(result):\n",
    "    try:\n",
    "        return result.find('a', {'data-tn-element':'jobTitle'}).text\n",
    "    except:\n",
    "        return 'NA'\n",
    "    \n",
    "def get_sal(result):\n",
    "    try:\n",
    "        return result.find('td', {'class':'snip'}).find('nobr').text\n",
    "    except:\n",
    "        return 'NA'\n",
    "    \n",
    "def get_link(result):\n",
    "    try:\n",
    "        return result.find(\"a\").attrs['href']\n",
    "                           \n",
    "    except:\n",
    "        return 'NA'\n",
    "def get_date(result):\n",
    "    try:\n",
    "        return result.find('span',{'class':'date'}).text\n",
    "    except:\n",
    "        return 'NA'\n",
    " \n",
    "    #roles that are required to run in the search bar\n",
    "indeed_roles = [\"Product Manager\"]\n",
    "\n",
    "\n",
    "#Running the for loop for a range of 10 job listings per page till 100 pages\n",
    "results = []\n",
    "\n",
    "for role in indeed_roles:\n",
    "    for start in range(0,100,10):\n",
    "        url = \"https://www.indeed.com/jobs?q=\"+role+\"&sort=date&l=United+States&start=\"+str(start)+\"\"  \n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "        #url = \"https://www.indeed.com/jobs?q=\"+role+\"&l=United+States&rbl=New+York%2C+NY&sort=date&ts=1529120086448&rq=1&fromage=last&start=\"+str(start)+\"&sort=&psf=advsrch\"\n",
    "        html = requests.get(url,headers=headers)\n",
    "        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "        for result in soup.find_all('div', {'class':' row result'}):\n",
    "            results.append(result)\n",
    "        sleep(2)\n",
    "\n",
    "#Storing the results in job_list\n",
    "\n",
    "job_list = pd.DataFrame(columns=['Company_Name','Contact Email','Contact Name','Contact Position','Job_Title','Date 1st Email Sent','Linkedin Sent Date','States','URLs','Date','Posted_date'])\n",
    "for entry in results:\n",
    "    company = get_comp(entry)\n",
    "    Contact_Email = \"\"\n",
    "    Contact_Name = \"\"\n",
    "    Contact_Position = \"\"\n",
    "    title = get_job(entry)\n",
    "    Date_1st_Email_Sent = \"\"\n",
    "    Linkedin_Sent_Date = \"\"\n",
    "    States = get_loc(entry)\n",
    "    URLs = get_link(entry)\n",
    "    Date = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "    Posted_date = get_date(entry)\n",
    "    job_list.loc[len(job_list)] = [company,Contact_Email,Contact_Name,Contact_Position,title,Date_1st_Email_Sent,Linkedin_Sent_Date, States,URLs,Date,Posted_date]\n",
    "    \n",
    "\n",
    "#dropping the duplicates with title and company as subsets and adding the .com to the link\n",
    "final_list = job_list.drop_duplicates(subset=[\"Job_Title\",\"Company_Name\"],keep = False)\n",
    "final_list['URLs'] = 'www.indeed.com' + final_list['URLs'].astype(str)\n",
    "\n",
    "List_ready = final_list\n",
    "\n",
    "# #Authorizing the key to access google spreadsheets\n",
    "\n",
    "# google_sheet = pygsheets.authorize(outh_file = \".jsonfilr\")\n",
    "\n",
    "# #Open spreadsheet\n",
    "# sheet = google_sheet.open(\"nameofthesheet\")\n",
    "\n",
    "\n",
    "# Staffing_Agencies = sheet.worksheet_by_title(\"Staffing Agencies - EXCLUSION\")\n",
    "# Big_Company = sheet.worksheet_by_title(\"Big Company - EXCLUSION\")\n",
    "# Digital_Marketing_Agencies = sheet.worksheet_by_title(\"Digital Marketing Agencies - EXCLUSION\")\n",
    "# Job_Title = sheet.worksheet_by_title(\"Job Title - EXCLUSIONS\")\n",
    "# Indeed_Database = sheet.worksheet_by_title(\"Indeed Database\")\n",
    "# Glassdoor_Database = sheet.worksheet_by_title(\"Glassdoor_Database\")\n",
    "# Linkedin = sheet.worksheet_by_title(\"Job Posting-Linkedin\")\n",
    "# Angel_List = sheet.worksheet_by_title(\"Job Posting- Angel List\")\n",
    "# Funded_Companies = sheet.worksheet_by_title(\"Funded Companies\")\n",
    "# Glassdoor = sheet.worksheet_by_title(\"Job Posting-Glassdoor\")\n",
    "# Indeed = sheet.worksheet_by_title(\"Indeed - OLD\")\n",
    "# indeed_vp = sheet.worksheet_by_title(\"VP - Indeed\")\n",
    "\n",
    "\n",
    "# #Pulling the sheets as df\n",
    "# Staffing_Agencies_df = Staffing_Agencies.get_as_df()\n",
    "# Big_Company_df= Big_Company.get_as_df()\n",
    "# Digital_Marketing_Agencies_df = Digital_Marketing_Agencies.get_as_df()\n",
    "# Job_Title_df = Job_Title.get_as_df()\n",
    "# Indeed_Database_df = Indeed_Database.get_as_df()\n",
    "# Glassdoor_Database_df = Glassdoor_Database.get_as_df()\n",
    "# Linkedin_df = Linkedin.get_as_df()\n",
    "# Angel_List_df = Angel_List.get_as_df()\n",
    "# Funded_Companies_df = Funded_Companies.get_as_df()\n",
    "# Glassdoor_df = Glassdoor.get_as_df()\n",
    "# Indeed_df = Indeed.get_as_df()\n",
    "# indeed_vp_df = indeed_vp.get_as_df()\n",
    "\n",
    "\n",
    "\n",
    "# #creating a list of companies coloumn for the above data frames\n",
    "# Staffing_Agencies_list = Staffing_Agencies_df.iloc[:,1].tolist()\n",
    "# Big_Company_list = Big_Company_df.iloc[:,0].tolist()\n",
    "# Digital_Marketing_Agencies_list = Digital_Marketing_Agencies_df.iloc[:,1].tolist()\n",
    "# Job_Title_list = Job_Title_df.iloc[:,0].tolist()\n",
    "# Indeed_Database_list = Indeed_Database_df.iloc[:,0].tolist()\n",
    "# Glassdoor_Database_list = Glassdoor_Database_df.iloc[:,0].tolist()\n",
    "# Linkedin_list = Linkedin_df.iloc[:,2].tolist()\n",
    "# Angel_List_list = Angel_List_df.iloc[:,2].tolist()\n",
    "# Funded_Companies_list = Funded_Companies_df.iloc[:,5].tolist()\n",
    "# Glassdoor_list = Glassdoor_df.iloc[:,2].tolist()\n",
    "# indeed_list = Indeed_df.iloc[:,4].tolist()\n",
    "\n",
    "\n",
    "\n",
    "# #removing the empty spaces from the list\n",
    "# Staffing_Agencies_list  = filter(None, Staffing_Agencies_list)\n",
    "# Big_Company_list = filter(None, Big_Company_list)\n",
    "# Digital_Marketing_Agencies_list = filter(None, Digital_Marketing_Agencies_list)\n",
    "# Job_Title_list = filter(None, Job_Title_list)\n",
    "# Indeed_Database_list = filter(None, Indeed_Database_list)\n",
    "# Glassdoor_Database_list = filter(None, Glassdoor_Database_list)\n",
    "# Linkedin_list = filter(None, Linkedin_list)\n",
    "# Angel_List_list = filter(None, Angel_List_list)\n",
    "# Funded_Companies_list= filter(None, Funded_Companies_list)\n",
    "# Glassdoor_list= filter(None, Glassdoor_list)\n",
    "# indeed_list = filter(None, indeed_list)\n",
    "\n",
    "\n",
    "# List_ready[\"Company_Name\"] = [x.replace(\"\\n\",\"\") for x in List_ready[\"Company_Name\"]]\n",
    "# List_ready[\"Company_Name\"] = [x.replace(\"\\n\\n\",\"\") for x in List_ready[\"Company_Name\"]]\n",
    "\n",
    "# #dropping the companies and staffing agencies that have already been scrapped\n",
    "# final1 = List_ready[~List_ready['Job_Title'].str.contains('|'.join(Job_Title_list),flags=re.IGNORECASE)]\n",
    "# final2 = final1[~final1['Company_Name'].str.contains('|'.join(indeed_list),flags=re.IGNORECASE)]\n",
    "# final3 = final2[~final2['Company_Name'].str.contains('|'.join(Staffing_Agencies_list),flags=re.IGNORECASE)]\n",
    "# final4 = final3[~final3['Company_Name'].str.contains('|'.join(Digital_Marketing_Agencies_list),flags=re.IGNORECASE)]\n",
    "# final5 = final4[~final4['Company_Name'].str.contains('|'.join(Big_Company_list),flags=re.IGNORECASE)]\n",
    "# final6 = final5[~final5['Company_Name'].str.contains('|'.join(Linkedin_list),flags=re.IGNORECASE)]\n",
    "# final7 = final6[~final6['Company_Name'].str.contains('|'.join(Angel_List_list),flags=re.IGNORECASE)]\n",
    "# final8 = final7[~final7['Company_Name'].str.contains('|'.join(Funded_Companies_list),flags=re.IGNORECASE)]\n",
    "# final9 = final8[~final8['Company_Name'].str.contains('|'.join(Glassdoor_list),flags=re.IGNORECASE)]\n",
    "# final10 = final9[~final9['Company_Name'].str.contains('|'.join(Glassdoor_Database_list),flags=re.IGNORECASE)]\n",
    "# final11 = final10[~final10['Company_Name'].str.contains('|'.join(Indeed_Database_list),flags=re.IGNORECASE)]\n",
    "# #final12 = final11[~final11['Company_Name'].str.contains('|'.join(indeed_vp_list),flags=re.IGNORECASE)]\n",
    "# print final11\n",
    "\n",
    "# final12_save = sheet.worksheet_by_title(\"VP - Indeed\")\n",
    "\n",
    "# final12_save.set_dataframe(final11,(1,1),copy_head=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Job Title, Location, URL]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Spread('prettyprinted','Product Gym - Job Boards')\n",
    "s.open_sheet(\"Glassdoor\")\n",
    "\n",
    "df = s.sheet_to_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.df_to_sheet(List_ready,index=False,replace=True,sheet=\"Glassdoor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
